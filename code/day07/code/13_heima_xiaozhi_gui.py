# é»‘é©¬å°æ™º - åŸºäºOllamaæœ¬åœ°å¤§æ¨¡å‹çš„è¯­éŸ³å¯¹è¯ç³»ç»Ÿ (GUIç‰ˆæœ¬)
import sys
import os
import time
import asyncio
import threading
from datetime import datetime

import pyaudio
import wave
import whisper
import edge_tts
import pygame
import ollama

from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QVBoxLayout, QHBoxLayout, 
    QTextEdit, QPushButton, QLabel, QWidget, QScrollArea,
    QFrame, QMessageBox, QProgressBar, QSplitter
)
from PyQt5.QtCore import QThread, pyqtSignal, Qt, QTimer
from PyQt5.QtGui import QFont, QPixmap, QPalette, QColor, QIcon

# pip install PyQt5 edge_tts pygame ollama pyaudio whisper

# --- å½•éŸ³é…ç½® ---
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
TEMP_WAVE_FILENAME = "xiaozhi_input.wav"
TEMP_TTS_FILENAME = "xiaozhi_response.mp3"
VOICE = "zh-CN-XiaoxiaoNeural"  # AIå›å¤ä½¿ç”¨çš„è¯­éŸ³

# Ollamaæ¨¡å‹é…ç½®
OLLAMA_MODEL = "qwen2:latest"

class HeimaXiaozhi:
    def __init__(self):
        self.conversation_history = [
            {"role": "system", "content": "ä½ æ˜¯é»‘é©¬å°æ™ºï¼Œä¸€ä¸ªç”±ä¼ æ™ºæ•™è‚²å¼€å‘çš„AIåŠ©æ‰‹ã€‚ä½ æ€§æ ¼æ´»æ³¼å‹å¥½ï¼Œå–„äºè§£ç­”ç¼–ç¨‹ã€å­¦ä¹ å’Œç”Ÿæ´»æ–¹é¢çš„é—®é¢˜ã€‚è¯·ç”¨ç®€æ´ã€äº²åˆ‡çš„è¯­è¨€å›å¤ï¼Œæ¯æ¬¡å›å¤æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚"}
        ]
    
    def chat(self, user_input):
        """ä¸Ollamaæœ¬åœ°å¤§æ¨¡å‹è¿›è¡Œå¯¹è¯"""
        try:
            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": user_input})
            
            # ä¿æŒå¯¹è¯å†å²åœ¨åˆç†é•¿åº¦å†…ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘10è½®å¯¹è¯ï¼‰
            if len(self.conversation_history) > 21:  # system + 10è½®å¯¹è¯(æ¯è½®2æ¡æ¶ˆæ¯)
                self.conversation_history = [self.conversation_history[0]] + self.conversation_history[-20:]
            
            # è°ƒç”¨Ollama API
            response = ollama.chat(
                model='qwen2:latest',
                messages=self.conversation_history
            )
            
            ai_response = response['message']['content']
            
            # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "assistant", "content": ai_response})
            
            return ai_response
            
        except Exception as e:
            return f"æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}"

class AudioRecorderThread(QThread):
    """å½•éŸ³çº¿ç¨‹"""
    finished = pyqtSignal(str)  # å½•éŸ³å®Œæˆä¿¡å·
    error = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self):
        super().__init__()
        self.is_recording = False
        
    def run(self):
        try:
            p = pyaudio.PyAudio()
            stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, 
                          input=True, frames_per_buffer=CHUNK)
            frames = []
            
            self.is_recording = True
            while self.is_recording:
                data = stream.read(CHUNK)
                frames.append(data)
                
            stream.stop_stream()
            stream.close()
            p.terminate()
            
            # ä¿å­˜å½•éŸ³æ–‡ä»¶
            wf = wave.open(TEMP_WAVE_FILENAME, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(p.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            
            self.finished.emit(TEMP_WAVE_FILENAME)
            
        except Exception as e:
            self.error.emit(f"å½•éŸ³å‡ºé”™: {str(e)}")
    
    def stop_recording(self):
        self.is_recording = False

class SpeechRecognitionThread(QThread):
    """è¯­éŸ³è¯†åˆ«çº¿ç¨‹"""
    finished = pyqtSignal(str)  # è¯†åˆ«å®Œæˆä¿¡å·
    error = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, audio_file, whisper_model):
        super().__init__()
        self.audio_file = audio_file
        self.whisper_model = whisper_model
        
    def run(self):
        try:
            result = self.whisper_model.transcribe(self.audio_file, language="Chinese")
            self.finished.emit(result["text"])
        except Exception as e:
            self.error.emit(f"è¯­éŸ³è¯†åˆ«å‡ºé”™: {str(e)}")

class ChatThread(QThread):
    """AIå¯¹è¯çº¿ç¨‹"""
    finished = pyqtSignal(str)  # å¯¹è¯å®Œæˆä¿¡å·
    error = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, user_input, xiaozhi):
        super().__init__()
        self.user_input = user_input
        self.xiaozhi = xiaozhi
        
    def run(self):
        try:
            response = self.xiaozhi.chat(self.user_input)
            self.finished.emit(response)
        except Exception as e:
            self.error.emit(f"AIå¯¹è¯å‡ºé”™: {str(e)}")

class TTSThread(QThread):
    """æ–‡æœ¬è½¬è¯­éŸ³çº¿ç¨‹"""
    finished = pyqtSignal(str)  # TTSå®Œæˆä¿¡å·
    error = pyqtSignal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, text):
        super().__init__()
        self.text = text
        
    def run(self):
        try:
            # ä½¿ç”¨asyncioåœ¨çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            async def generate_speech():
                communicate = edge_tts.Communicate(self.text, VOICE)
                await communicate.save(TEMP_TTS_FILENAME)
                return TEMP_TTS_FILENAME
            
            audio_file = loop.run_until_complete(generate_speech())
            loop.close()
            
            self.finished.emit(audio_file)
        except Exception as e:
            self.error.emit(f"è¯­éŸ³åˆæˆå‡ºé”™: {str(e)}")

class HeimaXiaozhiGUI(QMainWindow):
    def __init__(self):
        super().__init__()
        self.xiaozhi = HeimaXiaozhi()
        self.whisper_model = None
        self.conversation_count = 0
        
        # çº¿ç¨‹å¯¹è±¡
        self.recorder_thread = None
        self.recognition_thread = None
        self.chat_thread = None
        self.tts_thread = None
        
        self.init_ui()
        self.init_model()
        
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        self.setWindowTitle("ğŸ“ é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿ (GUIç‰ˆ)")
        self.setGeometry(100, 100, 900, 700)
        
        # è®¾ç½®çª—å£å›¾æ ‡å’Œæ ·å¼
        self.setStyleSheet("""
            QMainWindow {
                background-color: #f0f2f5;
            }
            QTextEdit {
                border: 2px solid #e1e8ed;
                border-radius: 10px;
                padding: 10px;
                font-size: 14px;
                background-color: white;
            }
            QPushButton {
                border: none;
                border-radius: 8px;
                padding: 12px 24px;
                font-size: 14px;
                font-weight: bold;
                color: white;
            }
            QPushButton:hover {
                transform: translateY(-2px);
            }
            QPushButton:pressed {
                transform: translateY(0px);
            }
            #recordBtn {
                background-color: #4CAF50;
            }
            #recordBtn:hover {
                background-color: #45a049;
            }
            #stopBtn {
                background-color: #f44336;
            }
            #stopBtn:hover {
                background-color: #da190b;
            }
            #clearBtn {
                background-color: #2196F3;
            }
            #clearBtn:hover {
                background-color: #1976D2;
            }
            QLabel {
                font-size: 14px;
                color: #333;
            }
            #titleLabel {
                font-size: 24px;
                font-weight: bold;
                color: #1976D2;
                padding: 10px;
            }
            #statusLabel {
                font-size: 12px;
                color: #666;
                padding: 5px;
            }
        """)
        
        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€
        main_layout = QVBoxLayout(central_widget)
        main_layout.setSpacing(15)
        main_layout.setContentsMargins(20, 20, 20, 20)
        
        # æ ‡é¢˜
        title_label = QLabel("ğŸ“ é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿ")
        title_label.setObjectName("titleLabel")
        title_label.setAlignment(Qt.AlignCenter)
        main_layout.addWidget(title_label)
        
        # å¯¹è¯æ˜¾ç¤ºåŒºåŸŸ
        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setMinimumHeight(400)
        main_layout.addWidget(self.chat_display)
        
        # çŠ¶æ€æ˜¾ç¤º
        self.status_label = QLabel("ğŸ¤– æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ...")
        self.status_label.setObjectName("statusLabel")
        main_layout.addWidget(self.status_label)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        main_layout.addWidget(self.progress_bar)
        
        # æŒ‰é’®åŒºåŸŸ
        button_layout = QHBoxLayout()
        
        self.record_btn = QPushButton("ğŸ¤ å¼€å§‹å½•éŸ³")
        self.record_btn.setObjectName("recordBtn")
        self.record_btn.clicked.connect(self.start_recording)
        button_layout.addWidget(self.record_btn)
        
        self.stop_btn = QPushButton("â¹ï¸ åœæ­¢å½•éŸ³")
        self.stop_btn.setObjectName("stopBtn")
        self.stop_btn.clicked.connect(self.stop_recording)
        self.stop_btn.setEnabled(False)
        button_layout.addWidget(self.stop_btn)
        
        self.clear_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯")
        self.clear_btn.setObjectName("clearBtn")
        self.clear_btn.clicked.connect(self.clear_chat)
        button_layout.addWidget(self.clear_btn)
        
        main_layout.addLayout(button_layout)
        
        # åº•éƒ¨ä¿¡æ¯
        info_label = QLabel("ğŸ’ª ä¼ æ™ºæ•™è‚²é»‘é©¬ç¨‹åºå‘˜ - è®©æ¯ä¸€ä¸ªäººéƒ½æœ‰äººç”Ÿå‡ºå½©çš„æœºä¼šï¼")
        info_label.setAlignment(Qt.AlignCenter)
        info_label.setStyleSheet("color: #666; font-size: 12px; padding: 10px;")
        main_layout.addWidget(info_label)
        
        # æ·»åŠ æ¬¢è¿ä¿¡æ¯
        self.add_system_message("ğŸ“ æ¬¢è¿ä½¿ç”¨é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼\n\nä½¿ç”¨è¯´æ˜ï¼š\n1. ğŸ¤ ç‚¹å‡»'å¼€å§‹å½•éŸ³'æŒ‰é’®å¼€å§‹è¯´è¯\n2. â¹ï¸ ç‚¹å‡»'åœæ­¢å½•éŸ³'ç»“æŸå½•éŸ³\n3. ğŸ§  ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«è¯­éŸ³å¹¶æ™ºèƒ½å›å¤\n4. ğŸ”Š AIå›å¤ä¼šè‡ªåŠ¨æ’­æ”¾è¯­éŸ³\n\nğŸŒŸ ç”±ä¼ æ™ºæ•™è‚²é»‘é©¬ç¨‹åºå‘˜æä¾›æŠ€æœ¯æ”¯æŒ")
        
    def init_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        def load_models():
            try:
                # åŠ è½½Whisperæ¨¡å‹
                self.status_label.setText("ğŸ¤– æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
                self.whisper_model = whisper.load_model("./base.pt")
                
                # æ£€æŸ¥Ollamaè¿æ¥
                self.status_label.setText("ğŸ”— æ­£åœ¨æ£€æŸ¥OllamaæœåŠ¡è¿æ¥...")
                response = ollama.chat(
                    model='qwen2:latest',
                    messages=[{'role': 'user', 'content': 'hello'}]
                )
                
                self.status_label.setText("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå¯ä»¥å¼€å§‹å¯¹è¯äº†ï¼")
                self.record_btn.setEnabled(True)
                
            except Exception as e:
                self.status_label.setText(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                QMessageBox.critical(self, "åˆå§‹åŒ–é”™è¯¯", 
                                   f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼š\n{str(e)}\n\nè¯·æ£€æŸ¥ï¼š\n1. base.ptæ–‡ä»¶æ˜¯å¦å­˜åœ¨\n2. OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ\n3. qwen2:latestæ¨¡å‹æ˜¯å¦å®‰è£…")
        
        # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½æ¨¡å‹
        threading.Thread(target=load_models, daemon=True).start()
        
    def add_system_message(self, message):
        """æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"<div style='color: #666; font-size: 12px; margin: 10px 0;'>[{timestamp}] {message}</div>"
        self.chat_display.append(formatted_message)
        
    def add_user_message(self, message):
        """æ·»åŠ ç”¨æˆ·æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"<div style='background-color: #e3f2fd; padding: 10px; margin: 5px 0; border-radius: 10px;'><b>ğŸ‘¤ ä½ è¯´ [{timestamp}]:</b><br>{message}</div>"
        self.chat_display.append(formatted_message)
        
    def add_ai_message(self, message):
        """æ·»åŠ AIæ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"<div style='background-color: #f3e5f5; padding: 10px; margin: 5px 0; border-radius: 10px;'><b>ğŸ¤– å°æ™ºå›å¤ [{timestamp}]:</b><br>{message}</div>"
        self.chat_display.append(formatted_message)
        
    def start_recording(self):
        """å¼€å§‹å½•éŸ³"""
        if not self.whisper_model:
            QMessageBox.warning(self, "è­¦å‘Š", "ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·ç¨å€™å†è¯•ï¼")
            return
            
        self.conversation_count += 1
        self.status_label.setText(f"ğŸ”´ æ­£åœ¨å½•éŸ³... (ç¬¬{self.conversation_count}è½®å¯¹è¯)")
        self.record_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        
        # å¯åŠ¨å½•éŸ³çº¿ç¨‹
        self.recorder_thread = AudioRecorderThread()
        self.recorder_thread.finished.connect(self.on_recording_finished)
        self.recorder_thread.error.connect(self.on_recording_error)
        self.recorder_thread.start()
        
    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        if self.recorder_thread and self.recorder_thread.isRunning():
            self.recorder_thread.stop_recording()
            self.status_label.setText("â¹ï¸ æ­£åœ¨åœæ­¢å½•éŸ³...")
            
    def on_recording_finished(self, audio_file):
        """å½•éŸ³å®Œæˆå¤„ç†"""
        self.record_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.status_label.setText("ğŸ§  æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
        
        # å¯åŠ¨è¯­éŸ³è¯†åˆ«çº¿ç¨‹
        self.recognition_thread = SpeechRecognitionThread(audio_file, self.whisper_model)
        self.recognition_thread.finished.connect(self.on_recognition_finished)
        self.recognition_thread.error.connect(self.on_recognition_error)
        self.recognition_thread.start()
        
    def on_recording_error(self, error_msg):
        """å½•éŸ³é”™è¯¯å¤„ç†"""
        self.record_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.status_label.setText("âŒ å½•éŸ³å¤±è´¥")
        QMessageBox.critical(self, "å½•éŸ³é”™è¯¯", error_msg)
        
    def on_recognition_finished(self, recognized_text):
        """è¯­éŸ³è¯†åˆ«å®Œæˆå¤„ç†"""
        self.add_user_message(recognized_text)
        
        # æ£€æŸ¥æ˜¯å¦è¦é€€å‡º
        if any(word in recognized_text.lower() for word in ['é€€å‡º', 'æ‹œæ‹œ', 'å†è§', 'bye', 'ç»“æŸ']):
            farewell_msg = "å¥½çš„ï¼Œå†è§ï¼å¾ˆé«˜å…´å’Œä½ èŠå¤©ï¼ŒæœŸå¾…ä¸‹æ¬¡è§é¢ï¼è®°å¾—å¤šæ¥é»‘é©¬ç¨‹åºå‘˜å­¦ä¹ å“¦ï¼"
            self.add_ai_message(farewell_msg)
            self.generate_and_play_speech(farewell_msg)
            return
            
        self.status_label.setText("ğŸ¤” å°æ™ºæ­£åœ¨æ€è€ƒ...")
        
        # å¯åŠ¨AIå¯¹è¯çº¿ç¨‹
        self.chat_thread = ChatThread(recognized_text, self.xiaozhi)
        self.chat_thread.finished.connect(self.on_chat_finished)
        self.chat_thread.error.connect(self.on_chat_error)
        self.chat_thread.start()
        
    def on_recognition_error(self, error_msg):
        """è¯­éŸ³è¯†åˆ«é”™è¯¯å¤„ç†"""
        self.status_label.setText("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥")
        QMessageBox.critical(self, "è¯†åˆ«é”™è¯¯", error_msg)
        
    def on_chat_finished(self, ai_response):
        """AIå¯¹è¯å®Œæˆå¤„ç†"""
        self.add_ai_message(ai_response)
        self.generate_and_play_speech(ai_response)
        
    def on_chat_error(self, error_msg):
        """AIå¯¹è¯é”™è¯¯å¤„ç†"""
        self.status_label.setText("âŒ AIå¯¹è¯å¤±è´¥")
        self.add_ai_message(f"æŠ±æ­‰ï¼Œå‡ºç°äº†é”™è¯¯ï¼š{error_msg}")
        
    def generate_and_play_speech(self, text):
        """ç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³"""
        self.status_label.setText("ğŸµ æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›å¤...")
        
        # å¯åŠ¨TTSçº¿ç¨‹
        self.tts_thread = TTSThread(text)
        self.tts_thread.finished.connect(self.on_tts_finished)
        self.tts_thread.error.connect(self.on_tts_error)
        self.tts_thread.start()
        
    def on_tts_finished(self, audio_file):
        """TTSå®Œæˆå¤„ç†"""
        self.status_label.setText("ğŸ”Š æ­£åœ¨æ’­æ”¾è¯­éŸ³å›å¤...")
        
        def play_audio():
            try:
                pygame.mixer.init()
                pygame.mixer.music.load(audio_file)
                pygame.mixer.music.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
                    
                pygame.mixer.quit()
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(audio_file):
                    os.remove(audio_file)
                    
                # æ›´æ–°çŠ¶æ€
                self.status_label.setText("âœ… å¯¹è¯å®Œæˆï¼Œå¯ä»¥ç»§ç»­å½•éŸ³")
                
            except Exception as e:
                self.status_label.setText(f"âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥: {str(e)}")
        
        # åœ¨åå°çº¿ç¨‹æ’­æ”¾éŸ³é¢‘
        threading.Thread(target=play_audio, daemon=True).start()
        
    def on_tts_error(self, error_msg):
        """TTSé”™è¯¯å¤„ç†"""
        self.status_label.setText("âŒ è¯­éŸ³åˆæˆå¤±è´¥")
        QMessageBox.warning(self, "è¯­éŸ³åˆæˆé”™è¯¯", error_msg)
        
    def clear_chat(self):
        """æ¸…ç©ºå¯¹è¯"""
        reply = QMessageBox.question(self, "ç¡®è®¤æ¸…ç©º", "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰å¯¹è¯è®°å½•å—ï¼Ÿ", 
                                   QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.chat_display.clear()
            self.conversation_count = 0
            # é‡ç½®å¯¹è¯å†å²
            self.xiaozhi = HeimaXiaozhi()
            self.add_system_message("ğŸ—‘ï¸ å¯¹è¯è®°å½•å·²æ¸…ç©ºï¼Œå¯ä»¥å¼€å§‹æ–°çš„å¯¹è¯äº†ï¼")
            
    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶å¤„ç†"""
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in [TEMP_WAVE_FILENAME, TEMP_TTS_FILENAME]:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        
        # åœæ­¢æ‰€æœ‰çº¿ç¨‹
        if self.recorder_thread and self.recorder_thread.isRunning():
            self.recorder_thread.stop_recording()
            self.recorder_thread.wait()
            
        event.accept()

def main():
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨ç¨‹åºä¿¡æ¯
    app.setApplicationName("é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿ")
    app.setApplicationVersion("2.0")
    
    # åˆ›å»ºä¸»çª—å£
    window = HeimaXiaozhiGUI()
    window.show()
    
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()