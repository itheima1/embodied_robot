# é»‘é©¬å°æ™º - åŸºäºOllamaæœ¬åœ°å¤§æ¨¡å‹çš„è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
import pyaudio
import wave
import whisper
import os
import time
import asyncio
import edge_tts
import pygame
import ollama
# pip install edge_tts pygame ollama

# --- å½•éŸ³é…ç½® ---
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
TEMP_WAVE_FILENAME = "xiaozhi_input.wav"
TEMP_TTS_FILENAME = "xiaozhi_response.mp3"
VOICE = "zh-CN-XiaoxiaoNeural"  # AIå›å¤ä½¿ç”¨çš„è¯­éŸ³

# Ollamaæ¨¡å‹é…ç½®
OLLAMA_MODEL = "qwen2:latest"  # å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹æ¨¡å‹åç§°

class HeimaXiaozhi:
    def __init__(self):
        self.conversation_history = [
            {"role": "system", "content": "ä½ æ˜¯é»‘é©¬å°æ™ºï¼Œä¸€ä¸ªç”±ä¼ æ™ºæ•™è‚²å¼€å‘çš„AIåŠ©æ‰‹ã€‚ä½ æ€§æ ¼æ´»æ³¼å‹å¥½ï¼Œå–„äºè§£ç­”ç¼–ç¨‹ã€å­¦ä¹ å’Œç”Ÿæ´»æ–¹é¢çš„é—®é¢˜ã€‚è¯·ç”¨ç®€æ´ã€äº²åˆ‡çš„è¯­è¨€å›å¤ï¼Œæ¯æ¬¡å›å¤æ§åˆ¶åœ¨100å­—ä»¥å†…ã€‚"}
        ]
    
    def chat(self, user_input):
        """ä¸Ollamaæœ¬åœ°å¤§æ¨¡å‹è¿›è¡Œå¯¹è¯"""
        try:
            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "user", "content": user_input})
            
            # ä¿æŒå¯¹è¯å†å²åœ¨åˆç†é•¿åº¦å†…ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘10è½®å¯¹è¯ï¼‰
            if len(self.conversation_history) > 21:  # system + 10è½®å¯¹è¯(æ¯è½®2æ¡æ¶ˆæ¯)
                self.conversation_history = [self.conversation_history[0]] + self.conversation_history[-20:]
            
            # è°ƒç”¨Ollama API
            response = ollama.chat(
                model='qwen2:latest',
                messages=self.conversation_history
            )
            
            ai_response = response['message']['content']
            
            # æ·»åŠ AIå›å¤åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "assistant", "content": ai_response})
            
            return ai_response
            
        except Exception as e:
            print(f"[!] Ollama APIè°ƒç”¨å‡ºé”™: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚å¯èƒ½éœ€è¦æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œã€‚"

def record_audio():
    """å½•åˆ¶éŸ³é¢‘"""
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    frames = []
    
    print("\n" + "="*50)
    print("  ğŸ¤ æŒ‰ä¸‹å›è½¦é”®å¼€å§‹å½•éŸ³ï¼ŒæŒ‰ä¸‹ Ctrl+C ç»“æŸå½•éŸ³")
    print("="*50)
    input("  è¯·æŒ‰å›è½¦é”®å¼€å§‹è¯´è¯...")
    
    print("\n[*] ğŸ”´ æ­£åœ¨å½•éŸ³... è¯·è¯´è¯")

    try:
        while True:
            data = stream.read(CHUNK)
            frames.append(data)
    except KeyboardInterrupt:
        print("[*] â¹ï¸ å½•éŸ³ç»“æŸ")

    stream.stop_stream()
    stream.close()
    p.terminate()

    wf = wave.open(TEMP_WAVE_FILENAME, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()
    
    return TEMP_WAVE_FILENAME

def transcribe_audio_with_whisper(audio_path, model):
    """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
    print("[*] ğŸ§  æ­£åœ¨è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œè¯·ç¨å€™...")
    result = model.transcribe(audio_path, language="Chinese")
    return result["text"]

async def text_to_speech(text, output_file=TEMP_TTS_FILENAME):
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜"""
    communicate = edge_tts.Communicate(text, VOICE)
    await communicate.save(output_file)
    return output_file

def play_audio(audio_file):
    """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
    try:
        pygame.mixer.init()
        pygame.mixer.music.load(audio_file)
        pygame.mixer.music.play()
        
        # ç­‰å¾…æ’­æ”¾å®Œæˆ
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
        
        pygame.mixer.quit()
    except Exception as e:
        print(f"[!] éŸ³é¢‘æ’­æ”¾å‡ºé”™: {e}")

async def speak_response(text):
    """AIè¯­éŸ³å›å¤"""
    print("[*] ğŸµ æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›å¤...")
    audio_file = await text_to_speech(text)
    print("[*] ğŸ”Š æ­£åœ¨æ’­æ”¾è¯­éŸ³å›å¤...")
    play_audio(audio_file)
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(audio_file):
        os.remove(audio_file)

def check_ollama_connection():
    """æ£€æŸ¥OllamaæœåŠ¡è¿æ¥"""
    try:
        # ç®€å•æµ‹è¯•è¿æ¥
        response = ollama.chat(
            model='qwen2:latest',
            messages=[{'role': 'user', 'content': 'hello'}]
        )
        print(f"[*] âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼æ¨¡å‹ qwen2:latest å·²å°±ç»ª")
        return True
    except Exception as e:
        print(f"[!] âŒ OllamaæœåŠ¡è¿æ¥å¤±è´¥: {e}")
        print("[!] è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå¯ä»¥å°è¯•è¿è¡Œ: ollama serve")
        print("[!] è¯·ç¡®ä¿å·²å®‰è£…qwen2:latestæ¨¡å‹ï¼Œå¯ä»¥è¿è¡Œ: ollama pull qwen2:latest")
        return False

async def main():
    """ä¸»ç¨‹åº"""
    print("[*] ğŸ¤– æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ (ç¡®ä¿åŒçº§æ–‡ä»¶å¤¹æœ‰base.ptæ–‡ä»¶)...")
    try:
        # åŠ è½½Whisperæ¨¡å‹
        model = whisper.load_model("./base.pt") 
        print("[*] âœ… Whisper æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"[!] âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("[!] è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚")
        return

    # æ£€æŸ¥Ollamaè¿æ¥
    print("[*] ğŸ”— æ­£åœ¨æ£€æŸ¥OllamaæœåŠ¡è¿æ¥...")
    if not check_ollama_connection():
        print("[!] âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œç¨‹åºé€€å‡º")
        return

    # åˆå§‹åŒ–é»‘é©¬å°æ™º
    xiaozhi = HeimaXiaozhi()
    
    print("\n" + "="*60)
    print("           ğŸ“ æ¬¢è¿ä½¿ç”¨é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼(Ollamaç‰ˆ)")
    print("="*60)
    print("è¯´æ˜ï¼š")
    print("1. ğŸ¤ æŒ‰å›è½¦å¼€å§‹å½•éŸ³ï¼ŒæŒ‰Ctrl+Cç»“æŸå½•éŸ³")
    print("2. ğŸ§  ç³»ç»Ÿä¼šè¯†åˆ«ä½ çš„è¯­éŸ³å¹¶ç”¨æœ¬åœ°AIæ™ºèƒ½å›å¤")
    print("3. ğŸšª è¯´'é€€å‡º'ã€'æ‹œæ‹œ'æˆ–'å†è§'å¯ä»¥ç»“æŸå¯¹è¯")
    print("4. ğŸ“¦ è¯·ç¡®ä¿å·²å®‰è£…: pip install edge_tts pygame ollama")
    print("5. ğŸ”§ è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
    print("6. ğŸ¤– å½“å‰ä½¿ç”¨æ¨¡å‹: qwen2:latest")
    print("7. ğŸŒŸ ç”±ä¼ æ™ºæ•™è‚²é»‘é©¬ç¨‹åºå‘˜æä¾›æŠ€æœ¯æ”¯æŒ")
    print("="*60)
    
    conversation_count = 0
    
    try:
        while True:
            conversation_count += 1
            print(f"\n--- ğŸ—£ï¸ ç¬¬ {conversation_count} è½®å¯¹è¯ ---")
            
            # å½•éŸ³
            audio_file = record_audio()
            
            # è¯­éŸ³è¯†åˆ«
            try:
                transcribed_text = transcribe_audio_with_whisper(audio_file, model)
                print(f"\n[è¯†åˆ«ç»“æœ] ğŸ‘¤ ä½ è¯´: {transcribed_text}")
                
                # æ£€æŸ¥æ˜¯å¦è¦é€€å‡º
                if any(word in transcribed_text.lower() for word in ['é€€å‡º', 'æ‹œæ‹œ', 'å†è§', 'bye', 'ç»“æŸ']):
                    farewell_msg = "å¥½çš„ï¼Œå†è§ï¼å¾ˆé«˜å…´å’Œä½ èŠå¤©ï¼ŒæœŸå¾…ä¸‹æ¬¡è§é¢ï¼è®°å¾—å¤šæ¥é»‘é©¬ç¨‹åºå‘˜å­¦ä¹ å“¦ï¼"
                    print(f"\n[å°æ™ºå›å¤] ğŸ¤– {farewell_msg}")
                    await speak_response(farewell_msg)
                    break
                
                # AIå›å¤
                print("[*] ğŸ¤” å°æ™ºæ­£åœ¨æ€è€ƒ...")
                response = xiaozhi.chat(transcribed_text)
                print(f"\n[å°æ™ºå›å¤] ğŸ¤– {response}")
                await speak_response(response)
                
            except Exception as e:
                print(f"[!] âŒ è¯­éŸ³è¯†åˆ«å‡ºé”™: {e}")
                continue
            
            finally:
                # åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                if os.path.exists(TEMP_WAVE_FILENAME):
                    os.remove(TEMP_WAVE_FILENAME)
    
    except KeyboardInterrupt:
        print("\n\n[*] ğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
    except Exception as e:
        print(f"\n[!] âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(TEMP_WAVE_FILENAME):
            os.remove(TEMP_WAVE_FILENAME)
        if os.path.exists(TEMP_TTS_FILENAME):
            os.remove(TEMP_TTS_FILENAME)
        print("\nğŸ“ æ„Ÿè°¢ä½¿ç”¨é»‘é©¬å°æ™ºè¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼(Ollamaç‰ˆ)")
        print("ğŸ’ª ä¼ æ™ºæ•™è‚²ï¼Œè®©æ¯ä¸€ä¸ªäººéƒ½æœ‰äººç”Ÿå‡ºå½©çš„æœºä¼šï¼")

if __name__ == "__main__":
    asyncio.run(main())